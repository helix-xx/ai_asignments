{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple classification model  \n",
    "use pytorch env  \n",
    "refer from d2l mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load Fashion-mnist data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import torchvision\n",
    "# from torchvision import transforms\n",
    "trans = torchvision.transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ../data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ../data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ../data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download data set\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root=\"../data\",train=True,transform=trans,download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root=\"../data\",train=False,transform=trans,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,num_workers=4)\n",
    "test_iter = data.DataLoader(mnist_test, batch_size, shuffle=False,num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens = 784, 10, 256\n",
    "\n",
    "W1 = nn.Parameter(torch.randn(\n",
    "    num_inputs, num_hiddens, requires_grad=True) * 0.01)\n",
    "b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))\n",
    "W2 = nn.Parameter(torch.randn(\n",
    "    num_hiddens, num_outputs, requires_grad=True) * 0.01)\n",
    "b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))\n",
    "\n",
    "params = [W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    a = torch.zeros_like(x)\n",
    "    return torch.max(x,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(x):\n",
    "    x = x.reshape((-1,num_inputs))\n",
    "    h = relu(x@W1+b1)               # @ represents matrix multiplication\n",
    "    return np.dot(h@W2,W2)+b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(reduce=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs, lr = 10,0.1\n",
    "updater =torch.optim.SGD(params,lr=lr)\n",
    "d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,updater)\n",
    "# def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):\n",
    "#     \"\"\"Train a model (defined in Chapter 3).\n",
    "\n",
    "#     Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
    "#     animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n",
    "#                         legend=['train loss', 'train acc', 'test acc'])\n",
    "#     for epoch in range(num_epochs):\n",
    "#         train_metrics = d2l.train_epoch_ch3(net, train_iter, loss, updater)\n",
    "#         test_acc = d2l.evaluate_accuracy(net, test_iter)\n",
    "#         animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "#     train_loss, train_acc = train_metrics\n",
    "#     assert train_loss < 0.5, train_loss\n",
    "#     assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "#     assert test_acc <= 1 and test_acc > 0.7, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.predict_ch3(net,test_iter)\n",
    "# def predict_ch3(net, test_iter, n=6):\n",
    "#     \"\"\"Predict labels (defined in Chapter 3).\n",
    "\n",
    "#     Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
    "#     for X, y in test_iter:\n",
    "#         break\n",
    "#     trues = d2l.get_fashion_mnist_labels(y)\n",
    "#     preds = d2l.get_fashion_mnist_labels(d2l.argmax(net(X), axis=1))\n",
    "#     titles = [true +'\\n' + pred for true, pred in zip(trues, preds)]\n",
    "#     d2l.show_images(\n",
    "#         d2l.reshape(X[0:n], (n, 28, 28)), 1, n, titles=titles[0:n])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('d2l': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a02d58d0bf31e81813ef44133234cbaee6fad28869458c427848087be9c14201"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
